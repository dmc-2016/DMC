{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ordering: tf\n"
     ]
    }
   ],
   "source": [
    "#know which Keras library is being used Theano or Tenserflow\n",
    "print \"using ordering:\", K.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d9b9bc82ed3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "imageFolder = \"-images\"\n",
    "\n",
    "image_dim = 3 #RGB\n",
    "\n",
    "imgs = {}\n",
    "\n",
    "for fileName in [\"Cairo_North_2000.jpg\", \"Cairo_North_2005.jpg\", \"Cairo_North_2010.jpg\", \"Cairo_North_2016.jpg\"]:\n",
    "    img = misc.imread(\"/\".join([imageFolder, fileName]))\n",
    "\n",
    "    if image_dim == 1 and len(img.shape) > 2: \n",
    "        img = img[:,:,0]\n",
    "        \n",
    "    img = img / 255.0\n",
    "    imgs[fileName] = img\n",
    "\n",
    "print \"Load data complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imgs[\"Cairo_North_2000.jpg\"]\n",
    "print \"image dimensions:\", img.shape\n",
    "\n",
    "imshow(img, cmap = plt.get_cmap('gray'), vmin = 0, vmax = 1,  interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "targetRes = 50\n",
    "\n",
    "img = imgs[\"Cairo_North_2000.jpg\"] #do for each image?is this the target image? change it then\n",
    "xStep = int( math.floor( float(img.shape[0]) / targetRes ) )\n",
    "yStep = int( math.floor( float(img.shape[1]) / targetRes ) )\n",
    "\n",
    "data = []\n",
    "\n",
    "for y in range(yStep):\n",
    "    for x in range(xStep):\n",
    "        \n",
    "        sample = []\n",
    "        \n",
    "        crop = imgs[\"Cairo_North_2000.jpg\"][x * targetRes : (x + 1) * targetRes, y * targetRes : (y + 1) * targetRes]\n",
    "        sample.append(crop)\n",
    "\n",
    "        for layer in [\"Cairo_North_2000.jpg\", \"Cairo_North_2005.jpg\", \"Cairo_North_2010.jpg\", \"Cairo_North_2016.jpg\"]:\n",
    "            target = imgs[layer][x * targetRes : (x + 1) * targetRes, y * targetRes : (y + 1) * targetRes]\n",
    "            target_val = int ( round( np.mean(target) ) )\n",
    "            sample.append(target_val)\n",
    "\n",
    "        data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_index = 100\n",
    "\n",
    "img = data[img_index][0]\n",
    "print \"image dimensions:\", img.shape\n",
    "print \"Value at time 0:\", (data[img_index][1])\n",
    "print \"Value at time 1:\", (data[img_index][2])\n",
    "print \"Value at time 2:\", (data[img_index][3])\n",
    "print \"Value at time 3:\", (data[img_index][4])\n",
    "\n",
    "imshow(img, cmap = plt.get_cmap('gray'), vmin = 0, vmax = 1,  interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recomp = {}\n",
    "\n",
    "for i, layer in enumerate([\"2000.jpg\", \"2005.jpg\", \"2010.jpg\", \"2016.jpg\"]):\n",
    "\n",
    "    recomp[layer] = np.ndarray((targetRes * xStep, targetRes * yStep), dtype=np.float32)\n",
    "\n",
    "    for y in range(yStep):\n",
    "        for x in range(xStep):\n",
    "            recomp[layer][x * targetRes : (x + 1) * targetRes, y * targetRes : (y + 1) * targetRes] = data[ y * xStep + x ][i+1]\n",
    "\n",
    "        \n",
    "for layer in [\"2000.jpg\", \"2005.jpg\", \"2010.jpg\", \"2016.jpg\"]:\n",
    "    \n",
    "    print layer\n",
    "    imshow(recomp[layer], cmap = plt.get_cmap('gray'), vmin = 0, vmax = 1,  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of classes\n",
    "num_classes = 2 #reducing number of classes \n",
    "\n",
    "# image dimensions\n",
    "img_rows, img_cols = X_train.shape[1],  X_train.shape[2]\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "batch_size = 128 # *increasing the number of training examples in one forward/backward pass--> making it too large can\n",
    "# cause the kernel to keep dying \n",
    "nb_epoch = 30\n",
    "\n",
    "# network architecture\n",
    "patch_size_1 = 4 #reducing the patch size for deeper neural network/more extensive connections\n",
    "patch_size_2 = 4\n",
    "patch_size_3 = 4 \n",
    "\n",
    "depth_1 = 40\n",
    "depth_2 = 50 #increasing depth size, but not too much to the hundreds \n",
    "depth_3 = 50\n",
    "\n",
    "pool_size = 2\n",
    "\n",
    "num_hidden_1 = 100\n",
    "num_hidden_2 = 100\n",
    "\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new Keras Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# add first convolutional layer to model and specify it's depth and filter size\n",
    "# for the first layer we also have to specify the size of each input image\n",
    "# which we calculated above\n",
    "model.add(Convolution2D(depth_1, patch_size_1, patch_size_1,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "# apply 'relu' activation function for first layer\n",
    "model.add(Activation('relu'))\n",
    "# apply max pooling to reduce the size of the image by a factor of 2\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "# repeat these operations for the second convolutional layer\n",
    "# this time Keras can figure out the input size \n",
    "# from the previous layer on it's own\n",
    "model.add(Convolution2D(depth_2, patch_size_2, patch_size_2,\n",
    "                        border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Convolution2D(depth_3, patch_size_3, patch_size_3,\n",
    "                        border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "\n",
    "# flatten the three-dimensional convolutional layer to a single layer of neurons\n",
    "model.add(Flatten())\n",
    "\n",
    "# add the first fully connected layer, applying 'relu' activation and dropout\n",
    "model.add(Dense(num_hidden_1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# add the second fully connected layer\n",
    "model.add(Dense(num_hidden_2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# add the final classification layer with the number of neurons \n",
    "# matching the number of classes we are trying to learn\n",
    "model.add(Dense(num_classes))\n",
    "\n",
    "# apply the 'softmax' activation to the final layer to convert the output to \n",
    "# a probability distribution\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print 'Test score:', score[0]\n",
    "print 'Test accuracy: {:.2%}'.format(score[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
