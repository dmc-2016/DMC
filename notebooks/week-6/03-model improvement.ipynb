{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 6.3 - Improving the model\n",
    "\n",
    "In this section of the lab, you will be asked to apply what you have learned to create a RNN model that can generate new sequences of text based on what it has learned from a large set of existing text. In this case we will be using the full text of Lewis Carroll's *Alice in Wonderland*. Your task for the assignment is to:\n",
    "\n",
    "- format the book text into a set of training data\n",
    "- define a RNN model in Keras based on one or more LSTM or GRU layers\n",
    "- train the model with the training data\n",
    "- use the trained model to generate new text\n",
    "\n",
    "Our previous model based on Obama's essay was prone to overfitting since there was not that much data to learn from. Thus, the generated text was either unintelligeable (not enough learning) or exactly replicated the training data (over-fitting). In this case, we are working with a much bigger data set, which should provide enough data to avoid over-fitting, but will also take more time to train. To improve your model, you can experiment with tuning the following hyper-parameters:\n",
    "\n",
    "- Use more than one recurrent layer and/or add more memory units (hidden neurons) to each layer. This will allow you to learn more complex structures in the data.\n",
    "- Use sequences longer than 100 characters, which will allow you to learn from patterns further back in time.\n",
    "- Change the way the sequences are generated. For example you could try to break up the text into real sentances using the periods, and then either cut or pad each sentance to make it 100 characters long.\n",
    "- Increase the number of training epochs, which will give the model more time to learn. Monitor the validation loss at each epoch to make sure the model is still improving at each epoch and is not overfitting the training data.\n",
    "- Add more dropout to the recurrent layers to minimize over-fitting.\n",
    "- Tune the batch size - try a batch size of 1 as a (very slow) baseline and larger sizes from there.\n",
    "- Experiment with scale factors (temperature) when interpreting the prediction probabilities.\n",
    "\n",
    "If you get an error such as `alloc error` or `out of memory error` during training it means that  your computer does not have enough RAM memory to store the model parameters or the batch of training data needed during a training step. If you run into this issue, try reducing the complexity of your model (both number and depth of layers) or the mini-batch size.\n",
    "\n",
    "The last three code blocks will use your trained model to generate a sequence of text based on a predefined seed. Do not change any of the code, but run it before submitting your assignment. Your work will be evaluated based on the quality of the generated text. A good result should be legible with decent grammar and spelling (this indicates a high level of learning), but the exact text should not be found anywhere in the actual text (this indicates over-fitting).\n",
    "\n",
    "Let's start by importing the libraries we will be using, and importing the full text from Alice in Wonderland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text: 141266\n",
      "text preview: alices adventures in wonderland\n",
      "\n",
      "lewis carroll\n",
      "\n",
      "the millennium fulcrum edition 3.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chapter i. down the rabbit-hole\n",
      "\n",
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, and what is the use of a book, thought alice without pictures or\n",
      "conversations?\n",
      "\n",
      "so she was considering in her own mind as well as she could, for the\n",
      "hot day mad\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "\n",
    "raw_text = re.sub('[^\\nA-Za-z0-9 ,.:;?!-]+', '', raw_text)\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "print \"length of text:\", n_chars\n",
    "print \"text preview:\", raw_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique characters found: 37\n",
      "a - maps to -> 11\n",
      "25 - maps to -> o\n",
      "Total sequences:  141166\n",
      "it, he was\n",
      "obliged to write with one finger for the rest of the day; and this was\n",
      "of very little use --> ,\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "# extract all unique characters in the text\n",
    "chars = sorted(list(set(raw_text)))\n",
    "n_vocab = len(chars)\n",
    "print \"number of unique characters found:\", n_vocab\n",
    "\n",
    "# create mapping of characters to integers and back\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# test our mapping\n",
    "print 'a', \"- maps to ->\", char_to_int[\"a\"]\n",
    "print 25, \"- maps to ->\", int_to_char[25]\n",
    "\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100 #HYPER PARAMETER\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    inputs.append(raw_text[i:i + seq_length])\n",
    "    outputs.append(raw_text[i + seq_length])\n",
    "    \n",
    "n_sequences = len(inputs)\n",
    "print \"Total sequences: \", n_sequences\n",
    "\n",
    "#shuffle input and output data\n",
    "indeces = range(len(inputs))\n",
    "random.shuffle(indeces)\n",
    "\n",
    "inputs = [inputs[x] for x in indeces]\n",
    "outputs = [outputs[x] for x in indeces]\n",
    "\n",
    "print inputs[0], \"-->\", outputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dims --> (141166, 100, 37)\n",
      "y dims --> (141166, 37)\n"
     ]
    }
   ],
   "source": [
    "# create two empty numpy array with the proper dimensions\n",
    "X = np.zeros((n_sequences, seq_length, n_vocab), dtype=np.bool)\n",
    "y = np.zeros((n_sequences, n_vocab), dtype=np.bool)\n",
    "\n",
    "# iterate over the data and build up the X and y data sets\n",
    "# by setting the appropriate indices to 1 in each one-hot vector\n",
    "for i, example in enumerate(inputs):\n",
    "    for t, char in enumerate(example):\n",
    "        X[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[outputs[i]]] = 1\n",
    "    \n",
    "print 'X dims -->', X.shape\n",
    "print 'y dims -->', y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.50)) #HYPER PARAMETER\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"a6-basic_LSTM.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(sentence, sample_length=50, diversity=0.35):\n",
    "    generated = sentence\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(sample_length):\n",
    "        x = np.zeros((1, X.shape[1], X.shape[2]))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = int_to_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 365s - loss: 2.7806 - val_loss: 2.3790\n",
      "----- generating with seed: room! no room! they cried out when they saw alice\n",
      "coming. theres plenty of room! said alice indignan\n",
      "room! no room! they cried out when they saw alice\n",
      "coming. theres plenty of room! said alice indignand woun he the che to the soure the he the whe aid the f rouee sat al  is the we the the the she al i\n",
      "room! no room! they cried out when they saw alice\n",
      "coming. theres plenty of room! said alice indignand thobudde ho seiligb\n",
      "la-ow lhee hoiborigg, ay,th thind ystin. ad iato ! sal. oug d olwatroik tit in\n",
      "epoch: 2 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 364s - loss: 2.3212 - val_loss: 2.1611\n",
      "----- generating with seed: nd half believed herself in\n",
      "wonderland, though she knew she had but to open them again, and all\n",
      "woul\n",
      "nd half believed herself in\n",
      "wonderland, though she knew she had but to open them again, and all\n",
      "woul the soudt worr and the soud on gar and the sate ar as ing the dart sous he the pid in the wat lout \n",
      "nd half believed herself in\n",
      "wonderland, though she knew she had but to open them again, and all\n",
      "woulu teal! sne\n",
      "\n",
      "igtao, shende sasreny, smoul  ora\n",
      "yep heafle\n",
      "\n",
      "ordanlf on hh canp,\n",
      "mhir pfoime, suic.\n",
      "ar\n",
      "epoch: 3 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 369s - loss: 2.1802 - val_loss: 2.0486\n",
      "----- generating with seed: ery politely, feeling quite\n",
      "pleased to have got into a conversation.\n",
      "\n",
      "you dont know much, said the d\n",
      "ery politely, feeling quite\n",
      "pleased to have got into a conversation.\n",
      "\n",
      "you dont know much, said the dound, in the buts bect and theuling on, and allice on it an and in it said the ance thed souther was\n",
      "ery politely, feeling quite\n",
      "pleased to have got into a conversation.\n",
      "\n",
      "you dont know much, said the dfupledp!e\n",
      "!o it pefrnowth; aidmeod and anoi!\n",
      "k-io.\n",
      "the alevradn. llyeveun.\n",
      " iu\n",
      "wamlidg terof,\n",
      "soik, \n",
      "epoch: 4 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 375s - loss: 2.0904 - val_loss: 1.9692\n",
      "----- generating with seed: th some curiosity. what a\n",
      "funny watch! she remarked. it tells the day of the month, and doesnt\n",
      "tell \n",
      "th some curiosity. what a\n",
      "funny watch! she remarked. it tells the day of the month, and doesnt\n",
      "tell of the hertering to the morelll you nount very at inde wether the what in the to ken. the doryound s\n",
      "th some curiosity. what a\n",
      "funny watch! she remarked. it tells the day of the month, and doesnt\n",
      "tell otl rafhy, soiss: but grinf rudtisp, in hht hevall.\n",
      "\n",
      "bovereg sten-elad.\n",
      "\n",
      "so the sanen, folist afrygn\n",
      "epoch: 5 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 366s - loss: 2.0215 - val_loss: 1.9080\n",
      "----- generating with seed: nt on, --found\n",
      "it advisable to go with edgar atheling to meet william and offer him the\n",
      "crown. willi\n",
      "nt on, --found\n",
      "it advisable to go with edgar atheling to meet william and offer him the\n",
      "crown. willing out said the that at it wated and the pore and sating aid and all the grothe wertone: en the dont\n",
      "nt on, --found\n",
      "it advisable to go with edgar atheling to meet william and offer him the\n",
      "crown. willie?\n",
      "\n",
      "berissids there! fhered the destrss.\n",
      "\n",
      "lavetlich sace mashe mas hing? the vice oung tous, s if jr\n",
      "epoch: 6 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 375s - loss: 1.9677 - val_loss: 1.8617\n",
      "----- generating with seed: s right, five! always lay the\n",
      "blame on others!\n",
      "\n",
      "youd better not talk! said five. i heard the queen s\n",
      "s right, five! always lay the\n",
      "blame on others!\n",
      "\n",
      "youd better not talk! said five. i heard the queen she manked alice and winl the whith and the could the mades the fort the call and what the herselligh\n",
      "s right, five! always lay the\n",
      "blame on others!\n",
      "\n",
      "youd better not talk! said five. i heard the queen sarpifes\n",
      "mf mill\n",
      "gah itco. oum.\n",
      "\n",
      "perd! \n",
      "afd you, the tusey upple,\n",
      "he wrupdon, think upole at, and cas\n",
      "epoch: 7 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 364s - loss: 1.9215 - val_loss: 1.8168\n",
      "----- generating with seed:  wanted much to know,\n",
      "but the dodo had paused as if it thought that somebody ought to speak,\n",
      "and no \n",
      " wanted much to know,\n",
      "but the dodo had paused as if it thought that somebody ought to speak,\n",
      "and no mere the looked the sant of the rither in to said the was rately the growh her alice was to the crab\n",
      " wanted much to know,\n",
      "but the dodo had paused as if it thought that somebody ought to speak,\n",
      "and no kert, thes, the gorys, she busnwes she treant\n",
      "ice uay vore thabe abecill, mas she don  louny viry es\n",
      "epoch: 8 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 363s - loss: 1.8854 - val_loss: 1.7850\n",
      "----- generating with seed: ngs may be different, said alice; all i know\n",
      "is, it would feel very queer to me.\n",
      "\n",
      "you! said the cate\n",
      "ngs may be different, said alice; all i know\n",
      "is, it would feel very queer to me.\n",
      "\n",
      "you! said the caterreace.\n",
      "\n",
      "for the catter the raster to nevery in a fertist the mome the had and then out it was a lit\n",
      "ngs may be different, said alice; all i know\n",
      "is, it would feel very queer to me.\n",
      "\n",
      "you! said the caterfof, i woned a fenghy yous sade; thius, he duct: the  mmtesuring to thet hant, whni s, ibtteeld bon\n",
      "epoch: 9 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 373s - loss: 1.8524 - val_loss: 1.7549\n",
      "----- generating with seed:  of the court.\n",
      "\n",
      "all this time the queen had never left off staring at the hatter, and,\n",
      "just as the d\n",
      " of the court.\n",
      "\n",
      "all this time the queen had never left off staring at the hatter, and,\n",
      "just as the duchess the griching it sintter be the to sead the firts sied the catsredone the more thing to the sa\n",
      " of the court.\n",
      "\n",
      "all this time the queen had never left off staring at the hatter, and,\n",
      "just as the dniter,\n",
      "suid you wange, you jery. i\n",
      "cherpehs the lame cained insw--op efots-arzilved, alide heidn, th\n",
      "epoch: 10 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 363s - loss: 1.8214 - val_loss: 1.7279\n",
      "----- generating with seed: me dead\n",
      "leaves that had fluttered down from the trees upon her face.\n",
      "\n",
      "wake up, alice dear! said her \n",
      "me dead\n",
      "leaves that had fluttered down from the trees upon her face.\n",
      "\n",
      "wake up, alice dear! said her all the king as the little save the wat the hame here the forre a the pary of the said the docs it w\n",
      "me dead\n",
      "leaves that had fluttered down from the trees upon her face.\n",
      "\n",
      "wake up, alice dear! said her comkly uncornover the- i demus, the gat, thermew!\n",
      "\n",
      "o foor!\n",
      "\n",
      "c mo\n",
      "che ather in an leas, as all\n",
      "youdju\n",
      "epoch: 11 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 373s - loss: 1.7980 - val_loss: 1.7078\n",
      "----- generating with seed: does the boots and shoes! she repeated\n",
      "in a wondering tone.\n",
      "\n",
      "why, what are your shoes done with? sai\n",
      "does the boots and shoes! she repeated\n",
      "in a wondering tone.\n",
      "\n",
      "why, what are your shoes done with? said the said to the dithers in the were to ive to get of see it the rook of she had and said the histe\n",
      "does the boots and shoes! she repeated\n",
      "in a wondering tone.\n",
      "\n",
      "why, what are your shoes done with? said alice bother, and do wattny nitem, lous sheelly kning gatlesinits by,\n",
      "remparding in tho begam very\n",
      "epoch: 12 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 371s - loss: 1.7707 - val_loss: 1.6872\n",
      "----- generating with seed: ke the look\n",
      "of things at all, as the game was in such confusion that she never knew\n",
      "whether it was h\n",
      "ke the look\n",
      "of things at all, as the game was in such confusion that she never knew\n",
      "whether it was her head not and began in a mory the a dowf to be of the his as she began and not gat for the harse s\n",
      "ke the look\n",
      "of things at all, as the game was in such confusion that she never knew\n",
      "whether it was herpee.\n",
      "\n",
      "oh aroute!,\n",
      "he\n",
      "plisn; tnow! hal--appeos.\n",
      "\n",
      "elleden as the listoush. sat delt, if the leas eas\n",
      "epoch: 13 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 367s - loss: 1.7494 - val_loss: 1.6753\n",
      "----- generating with seed: tes she heard\n",
      "a voice outside, and stopped to listen.\n",
      "\n",
      "mary ann! mary ann! said the voice. fetch me \n",
      "tes she heard\n",
      "a voice outside, and stopped to listen.\n",
      "\n",
      "mary ann! mary ann! said the voice. fetch me the hooken it wat like a down and as the coulf wat ligel that so so were a dout not the bous in the \n",
      "tes she heard\n",
      "a voice outside, and stopped to listen.\n",
      "\n",
      "mary ann! mary ann! said the voice. fetch me negring little reat stes\n",
      ";o toat.\n",
      "\n",
      "  w--whes, mot neyopono ad mace at ohk\n",
      "yeminustsekus timn ad whom\n",
      "epoch: 14 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 364s - loss: 1.7325 - val_loss: 1.6563\n",
      "----- generating with seed: alice sharply, for she was beginning to\n",
      "feel a little worried.\n",
      "\n",
      "just about as much right, said the d\n",
      "alice sharply, for she was beginning to\n",
      "feel a little worried.\n",
      "\n",
      "just about as much right, said the door of the wither alace.\n",
      "\n",
      "of the didnent was the door alice said to the king to said the haster of t\n",
      "alice sharply, for she was beginning to\n",
      "feel a little worried.\n",
      "\n",
      "just about as much right, said the dothet hade, the rusther beot fatten-uce all stimt guoped inxe hxaven, ims anoule the omite whster yo\n",
      "epoch: 15 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 372s - loss: 1.7067 - val_loss: 1.6419\n",
      "----- generating with seed: boots every christmas.\n",
      "\n",
      "and she went on planning to herself how she would manage it. they must\n",
      "go by\n",
      "boots every christmas.\n",
      "\n",
      "and she went on planning to herself how she would manage it. they must\n",
      "go by the wanting and she for and thong the queen of the would not it was the moust in the march as all a\n",
      "boots every christmas.\n",
      "\n",
      "and she went on planning to herself how she would manage it. they must\n",
      "go bytele agehtsund; esgoo, sheow! that as, was troee an\n",
      "yup. is-witheeted, blyen ik theie! suid they man\n",
      "epoch: 16 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 363s - loss: 1.6925 - val_loss: 1.6352\n",
      "----- generating with seed:  voice, thats bill, thought\n",
      "alice, well, i hardly know--no more, thank ye; im better now--but im\n",
      "a d\n",
      " voice, thats bill, thought\n",
      "alice, well, i hardly know--no more, thank ye; im better now--but im\n",
      "a doon it was she said the irther peating to see beant of the very there a little she went in a the and\n",
      " voice, thats bill, thought\n",
      "alice, well, i hardly know--no more, thank ye; im better now--but im\n",
      "a dight at all cumining poommeyoh, saed hi know, whiks teall,\n",
      "hacp, the mrce one:eedf\n",
      "ind; curauning to\n",
      "epoch: 17 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 363s - loss: 1.6744 - val_loss: 1.6227\n",
      "----- generating with seed: ous as it can be, said the gryphon.\n",
      "\n",
      "it all came different! the mock turtle repeated thoughtfully. i\n",
      "ous as it can be, said the gryphon.\n",
      "\n",
      "it all came different! the mock turtle repeated thoughtfully. it nead it said alice sead couldne well the say have a donn she was soon whote it the duchess as she \n",
      "ous as it can be, said the gryphon.\n",
      "\n",
      "it all came different! the mock turtle repeated thoughtfully. ies everquise\n",
      "leusey no\n",
      "leorif affursing.\n",
      "\n",
      "when all the beconted to the orgo fon one..\n",
      "\n",
      "lorily thim,,\n",
      "epoch: 18 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 365s - loss: 1.6599 - val_loss: 1.6064\n",
      "----- generating with seed: of the suppressed guinea-pigs,\n",
      "filled the air, mixed up with the distant sobs of the miserable mock\n",
      "\n",
      "of the suppressed guinea-pigs,\n",
      "filled the air, mixed up with the distant sobs of the miserable mock\n",
      "torther said the dono asing to ting said it and the dorat it to like thing the dormouse was said, an\n",
      "of the suppressed guinea-pigs,\n",
      "filled the air, mixed up with the distant sobs of the miserable mock\n",
      "to-sanving they someictself thing lawls,\n",
      "every, arl all ple fard! as the saice, what a dowant!\n",
      "\n",
      "she \n",
      "epoch: 19 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 365s - loss: 1.6429 - val_loss: 1.5985\n",
      "----- generating with seed: ain. in\n",
      "a minute or two the caterpillar took the hookah out of its mouth\n",
      "and yawned once or twice, a\n",
      "ain. in\n",
      "a minute or two the caterpillar took the hookah out of its mouth\n",
      "and yawned once or twice, and could hear alack the whate as of that athers, and she think i wonter ad it head look of the sand,\n",
      "ain. in\n",
      "a minute or two the caterpillar took the hookah out of its mouth\n",
      "and yawned once or twice, and the hardly sand were on.-!, was duan-twally: tuph ateamicunby sbow! donhed king fince sging.\n",
      "\n",
      "her\n",
      "epoch: 20 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 367s - loss: 1.6301 - val_loss: 1.5919\n",
      "----- generating with seed:  poor speaker, said the king.\n",
      "\n",
      "here one of the guinea-pigs cheered, and was immediately suppressed b\n",
      " poor speaker, said the king.\n",
      "\n",
      "here one of the guinea-pigs cheered, and was immediately suppressed be of the caterpiling\n",
      "the farth here hard near so the parss, she was domont began to hard the suches \n",
      " poor speaker, said the king.\n",
      "\n",
      "here one of the guinea-pigs cheered, and was immediately suppressed buen iv to so\n",
      "yim waine shall nool utpere to, said the queen; and os getows\n",
      "ffom in a aung\n",
      "pig hs\n",
      "pre\n",
      "epoch: 21 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 363s - loss: 1.6175 - val_loss: 1.5820\n",
      "----- generating with seed: e look\n",
      "of things at all, as the game was in such confusion that she never knew\n",
      "whether it was her tu\n",
      "e look\n",
      "of things at all, as the game was in such confusion that she never knew\n",
      "whether it was her turting her hard doon in the time to gat the duchess was a little said and reast better i the puchers \n",
      "e look\n",
      "of things at all, as the game was in such confusion that she never knew\n",
      "whether it was her turts.\n",
      "\n",
      "see in\n",
      "a thing-asniwed as hoteekf! fom thoogs timh! to rebeat ster-aed conlle in ohen stabbed,\n",
      "epoch: 22 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 367s - loss: 1.6065 - val_loss: 1.5760\n",
      "----- generating with seed:  all in bed!\n",
      "on various pretexts they all moved off, and alice was soon left alone.\n",
      "\n",
      "i wish i hadnt \n",
      " all in bed!\n",
      "on various pretexts they all moved off, and alice was soon left alone.\n",
      "\n",
      "i wish i hadnt said gaid the dorup, she said to herself, and the mouse was could not gen the mouse was and the sorm\n",
      " all in bed!\n",
      "on various pretexts they all moved off, and alice was soon left alone.\n",
      "\n",
      "i wish i hadnt ie a sosehass cad talking  etpint abprintsed prigped in i set wert, but ee; thepertall to all quite \n",
      "epoch: 23 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 367s - loss: 1.5929 - val_loss: 1.5683\n",
      "----- generating with seed: lice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to \n",
      "lice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to me a canterd, and was the mouse and is would the jury with a mush her off the morse, and the mouse s\n",
      "lice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to ghe pellied a durciley dun. whly dopn? quite would tems.\n",
      "\n",
      "       and gave\n",
      "    hex touthd juss two wi\n",
      "epoch: 24 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 364s - loss: 1.5818 - val_loss: 1.5633\n",
      "----- generating with seed: ught; and how funny itll seem, sending\n",
      "presents to ones own feet! and how odd the directions will lo\n",
      "ught; and how funny itll seem, sending\n",
      "presents to ones own feet! and how odd the directions will low, said the duchess.\n",
      "\n",
      "when alice thenesterst this a mouse to the court would be it lever hear the co\n",
      "ught; and how funny itll seem, sending\n",
      "presents to ones own feet! and how odd the directions will lookibgo ther, said the kinclitg.\n",
      "\n",
      "the whate\n",
      "quist on i gone\n",
      "be to jeat litklay then pry, and snow! th\n",
      "epoch: 25 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 372s - loss: 1.5681 - val_loss: 1.5590\n",
      "----- generating with seed: raphy: then drawling--the drawling-master was an old conger-eel,\n",
      "that used to come once a week: he t\n",
      "raphy: then drawling--the drawling-master was an old conger-eel,\n",
      "that used to come once a week: he tond time so the tone and the wither all the hatter; and the got would the belint seemed to to could,\n",
      "raphy: then drawling--the drawling-master was an old conger-eel,\n",
      "that used to come once a week: he tous bew\n",
      " f hereld on evary,\n",
      "sed in lee aldiden wouted, thenrilins undonund ot do rauch!\n",
      " itsleen bno\n",
      "epoch: 26 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 372s - loss: 1.5605 - val_loss: 1.5552\n",
      "----- generating with seed: i never thought about it, said alice. why?\n",
      "\n",
      "it does the boots and shoes. the gryphon replied very so\n",
      "i never thought about it, said alice. why?\n",
      "\n",
      "it does the boots and shoes. the gryphon replied very soon. and the mechention the jury of hear, and will it was a little seed i made on the reasing to the \n",
      "i never thought about it, said alice. why?\n",
      "\n",
      "it does the boots and shoes. the gryphon replied very sonn!\n",
      "\n",
      "as hnow prrhidn you sif; way whith yinound enawy. spee, tales ay\n",
      "i sound cullo. which was siss \n",
      "epoch: 27 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 369s - loss: 1.5487 - val_loss: 1.5504\n",
      "----- generating with seed: the cat.\n",
      "\n",
      "i said pig, replied alice; and i wish you wouldnt keep appearing and\n",
      "vanishing so suddenly\n",
      "the cat.\n",
      "\n",
      "i said pig, replied alice; and i wish you wouldnt keep appearing and\n",
      "vanishing so suddenly how a pact of at the morse wor ont in whet it went on and a mancher, said the gottonself as which s\n",
      "the cat.\n",
      "\n",
      "i said pig, replied alice; and i wish you wouldnt keep appearing and\n",
      "vanishing so suddenly.\n",
      "\n",
      "the whith round anmthere, and soon the loors woudds\n",
      "arreeding with way them, ask olouto the ora!\n",
      "\n",
      "epoch: 28 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 376s - loss: 1.5409 - val_loss: 1.5499\n",
      "----- generating with seed: said the lory, with a shiver.\n",
      "\n",
      "i beg your pardon! said the mouse, frowning, but very politely: did\n",
      "y\n",
      "said the lory, with a shiver.\n",
      "\n",
      "i beg your pardon! said the mouse, frowning, but very politely: did\n",
      "you mante of the tore, and the were and looked of thats she was she sool do to be the room, and the w\n",
      "said the lory, with a shiver.\n",
      "\n",
      "i beg your pardon! said the mouse, frowning, but very politely: did\n",
      "you, puctredenten like sabousing\n",
      "and a elk among incalice fruloof! to kus am ut onre myone-\n",
      "your, as \n",
      "epoch: 29 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 366s - loss: 1.5292 - val_loss: 1.5453\n",
      "----- generating with seed: g come up again, dear! i\n",
      "shall only look up and say who am i then? tell me that first, and then,\n",
      "if \n",
      "g come up again, dear! i\n",
      "shall only look up and say who am i then? tell me that first, and then,\n",
      "if you mouse that it was of the enter.\n",
      "\n",
      "the patter in a to got to now, what i wintire to every. all she\n",
      "g come up again, dear! i\n",
      "shall only look up and say who am i then? tell me that first, and then,\n",
      "if i pllasnas withe, manter sherell\n",
      "mo the ativer.\n",
      "waw a ound hampelffidco, said the frystance,\n",
      "\n",
      "by the\n",
      "epoch: 30 / 30\n",
      "Train on 112932 samples, validate on 28234 samples\n",
      "Epoch 1/1\n",
      "112932/112932 [==============================] - 375s - loss: 1.5205 - val_loss: 1.5449\n",
      "----- generating with seed: ht be some sense in your knocking, the footman went on\n",
      "without attending to her, if we had the door \n",
      "ht be some sense in your knocking, the footman went on\n",
      "without attending to her, if we had the door all have and the cat diden, it in a set she took the louse, but that it fall things of she was so ne\n",
      "ht be some sense in your knocking, the footman went on\n",
      "without attending to her, if we had the door a list,, bus mimeff soas began hind that was noviced for and hid favel arieven! the\n",
      "kine, and, on, s\n"
     ]
    }
   ],
   "source": [
    "epochs = 30 #HYPER PARAMETER\n",
    "prediction_length = 100\n",
    "\n",
    "for iteration in range(epochs):\n",
    "    \n",
    "    print 'epoch:', iteration + 1, '/', epochs\n",
    "    #HYPER PARAMETER\n",
    "    model.fit(X, y, validation_split=0.2, batch_size=256, nb_epoch=1, callbacks=callbacks_list)\n",
    "    \n",
    "    # get random starting point for seed\n",
    "    start_index = random.randint(0, len(raw_text) - seq_length - 1)\n",
    "    # extract seed sequence from raw text\n",
    "    seed = raw_text[start_index: start_index + seq_length]\n",
    "    \n",
    "    print '----- generating with seed:', seed\n",
    "    \n",
    "    for diversity in [0.5, 1.2]:\n",
    "        generate(seed, prediction_length, diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not change this code, but run it before submitting your assignment to generate the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(sentence, sample_length=50, diversity=0.35):\n",
    "    generated = sentence\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(sample_length):\n",
    "        x = np.zeros((1, X.shape[1], X.shape[2]))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = int_to_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this time alice waited patiently until it chose to speak again. in a minute or two the caterpillar tone. i was this it was bestself ho to see would said and the\n",
      "ghented without hall was a look as it was that\n",
      "dorsat the cat she was going in a large, said the caterpillar said and cours leaged on the came the said the hister somethoug, and the caterpillar minentend the round the cook to the astenst to me dore the dot ot the dormouse becanting and said to alice, as it was to the cat of the sagain, and she was only as the dormouse said to the caterpillar, but the rome to me she would mose on the gr\n"
     ]
    }
   ],
   "source": [
    "prediction_length = 500\n",
    "seed = \"this time alice waited patiently until it chose to speak again. in a minute or two the caterpillar t\"\n",
    "\n",
    "generate(seed, prediction_length, .50)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
